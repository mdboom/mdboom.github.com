<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Boom! Michael Droettboom's blog - misc</title><link href="http://droettboom.com/" rel="alternate"></link><link href="http://droettboom.com/feeds/misc.atom.xml" rel="self"></link><id>http://droettboom.com/</id><updated>2019-11-01T15:40:00-04:00</updated><entry><title>This Week in Glean: November 1, 2019</title><link href="http://droettboom.com/blog/2019/11/01/this-week-in-glean-november-1-2019/" rel="alternate"></link><published>2019-11-01T15:20:00-04:00</published><updated>2019-11-01T15:40:00-04:00</updated><author><name>Michael Droettboom</name></author><id>tag:droettboom.com,2019-11-01:/blog/2019/11/01/this-week-in-glean-november-1-2019/</id><summary type="html">&lt;p&gt;When data goes wrong&lt;/p&gt;</summary><content type="html">&lt;p&gt;(“This Week in Glean” is a series of blog posts that the Glean Team at Mozilla is using to try to communicate better about our work. They could be release notes, documentation, hopes, dreams, or whatever: so long as it is inspired by Glean. The last two posts are &lt;a href="https://chuttenblog.wordpress.com/2019/10/17/this-week-in-glean-glean-on-desktop-project-fog/"&gt;here&lt;/a&gt; and &lt;a href="https://fnordig.de/2019/10/24/this-week-in-glean/"&gt;here&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;This week in Glean, we bring you a detective story from the Mozilla telemetry beat.  It's a story about how fixing things can often break things in unexpected ways.  It's about how things that may work perfectly in the lab, suddenly fail in the wild at scale.  And it's about how our team used all of the data sources at our disposal to solve a problem.&lt;/p&gt;
&lt;p&gt;Glean is a new effort at Mozilla to collect telemetry based on lessons from our past experiences that can be used across a number of our products and better support our &lt;a href="https://www.mozilla.org/en-US/about/policy/lean-data/"&gt;lean data practices&lt;/a&gt;.  It is currently being used to collect telemetry from &lt;a href="https://blog.mozilla.org/futurereleases/2019/06/27/reinventing-firefox-for-android-a-preview/"&gt;Firefox Preview for Android&lt;/a&gt;, but will be rolling out to more Mozilla products in the coming months.&lt;/p&gt;
&lt;p&gt;When using Firefox Preview, the browser makes measurements (or telemetry) about its usage and how it's performing.  Users can choose to disable telemetry if they prefer, however the data from the rest provides us with key insights that allow us to build stable and performant products that meet the needs of our users.  This telemetry is periodically sent to Mozilla in bundles called "&lt;a href="https://mozilla.github.io/glean/book/user/pings/index.html"&gt;pings&lt;/a&gt;", all of which is orchestrated on Firefox's behalf by the Glean SDK.&lt;/p&gt;
&lt;p&gt;The Glean SDK sends a few different kinds of pings, but the two that are relevant to our story are the &lt;a href="https://mozilla.github.io/glean/book/user/pings/metrics.html"&gt;metrics&lt;/a&gt; ping and &lt;a href="https://mozilla.github.io/glean/book/user/pings/baseline.html"&gt;baseline&lt;/a&gt; ping.  The metrics ping is sent once a day at 04:00 local time, if the user used the application in the last 24 hours.  The baseline ping contains minimal data, but is sent more often: every time the application "goes to background". This happens when the user switches to another application or the device goes to sleep.  Given how people normally use their smartphones, the browser "goes to background" a few times a day, so one would expect to see baseline pings occuring more often than metrics pings.&lt;/p&gt;
&lt;p&gt;Not long after the release of Firefox Preview, we noticed that we were getting a metrics ping every 24 hours from each user, even if they hadn't used the browser during that period.  This wastes bandwidth, both for us and our users, since there's no need to send data if there haven't been any changes.&lt;/p&gt;
&lt;p&gt;The bug was happening because every time Glean sent a metrics ping at 4am, it would just go ahead and schedule the next one to be sent 24 hours later. Android doesn't provide a lot of good options to solve this problem. The solution we arrived at is that Glean would schedule the ping for the next 04:00 only if the user is actually using the application at the time. If they aren't using it, we'll just check the next time the user opens the app, and schedule it for the following 04:00 at that time. Android provides an API that can tell our app when the app goes to foreground and background (among other things) called the "&lt;a href="https://developer.android.com/topic/libraries/architecture/lifecycle"&gt;LifecycleObserver API&lt;/a&gt;". Using that bit of information, Glean can know when the user is using the app and schedule our next metrics ping accordingly.&lt;/p&gt;
&lt;p&gt;We merged &lt;a href="https://github.com/mozilla-mobile/android-components/pull/3993"&gt;this fix&lt;/a&gt;, feeling we had squashed that bug and moved on.  But our jaws dropped when we saw the following graph:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Glean metrics graph" src="http://droettboom.com/images/glean-pings.png"&gt;&lt;/p&gt;
&lt;p&gt;The graph shows the number of clients that sent a baseline ping (green), metrics ping (red) or both a baseline and metrics ping (blue).  Around August 20, when we fixed that bug, the number of metrics pings went down (as expected), but the number of baseline pings went down even more, such that there were now fewer baseline pings than metrics pings.  How could that possibly be?&lt;/p&gt;
&lt;p&gt;We scratched our heads for a few days over this, methodically looking over of the other changes that occurred during that timeframe that may have caused this strange outcome in the data.  One by one, all other options were eliminated until all signs pointed to that "fix" for the metrics ping.  But understanding how that fix could be connected to this behavior remained elusive.&lt;/p&gt;
&lt;p&gt;It turned out the answer lay hidden in our crash data.  In addition to the Glean telemetry, Firefox Preview uses Sentry to collect reports about application crashes.  These reports contain "backtraces", or specific information about where in the code the crash occurred.  For some time, we had seen crash reports that pointed at Android's Lifecycle Observer API, but they were of such low frequency that we hadn't invested the effort to investigate further.  Around the time of the "fix" however, there was an uptick in these kinds of crashes. &lt;/p&gt;
&lt;p&gt;It turns out the Lifecycle Observer API has an &lt;a href="https://issuetracker.google.com/issues/138953075#comment2"&gt;undocumented limitation&lt;/a&gt; that it wasn't designed to be called in the way we were calling it (off of the main thread of execution).  This caused the Lifecycle Observer to randomly fail, but only sometimes, and only for a fraction of users in the wild.  I, personally, have never been able to reproduce the behavior -- we know about it only because Firefox Preview is running on thousands of devices in the world at large and they report back through Sentry.&lt;/p&gt;
&lt;p&gt;When the Lifecycle Observer does fail, two interesting things happen in tandem:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the metrics ping, Glean no longer knows when the application is being used, so it sends the metrics ping &lt;strong&gt;more often&lt;/strong&gt; than it should.&lt;/li&gt;
&lt;li&gt;The baseline ping is triggered directly from the Lifecycle Observer when the application goes to background. So when the Lifecycle Observer fails, Glean sends the baseline ping &lt;strong&gt;less often&lt;/strong&gt; than we should.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two things in combination are what caused the red and green lines to cross and the fabric of space-time to become unraveled.  The culprit is most likely that the fix added a second use of the Lifecycle Observer to the application: it was now being used both to handle the metrics ping and the baseline ping. Using it twice (and potentially concurrently) was enough to push a long latent crash problem into the monster that ate our data. &lt;/p&gt;
&lt;p&gt;These sorts of puzzles can be very frustrating until they reveal themselves.  Having a great team to brainstorm hypotheses with, and a common mission to find a "cause" without a "blame"  is incredibly valuable.  Thanks to everyone on the Glean team: Alessio Placitelli, Travis Long, Jan-Erik Rediger, Georg Fritzsche, Chris Hutten-Czapski and Beatriz Rizental.&lt;/p&gt;
&lt;p&gt;Join us next week.  Who knows what we'll find in the icy fjords of Glean land...&lt;/p&gt;</content><category term="glean"></category><category term="data"></category></entry></feed>